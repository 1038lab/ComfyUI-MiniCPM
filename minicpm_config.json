{
	"model_settings": {
		"context_window": 4096,
		"gpu_layers": -1,
		"cpu_threads": 4,
		"default_max_tokens": 1024,
		"default_temperature": 0.7,
		"default_top_p": 0.9,
		"default_top_k": 100,
		"default_repetition_penalty": 1.10,
		"default_system_prompt": "You are MiniCPM-V, a helpful, concise and knowledgeable vision-language assistant. Answer directly and stay on task."
	},
	"prompt_types": {
		"Describe": "Describe this image in detail.",
		"Caption": "Write a concise caption for this image.",
		"Analyze": "Analyze the main elements and scene in this image.",
		"Identify": "What objects and subjects do you see in this image?",
		"Explain": "Explain what's happening in this image.",
		"List": "List the main objects visible in this image.",
		"Scene": "Describe the scene and setting of this image.",
		"Details": "What are the key details in this image?",
		"Summarize": "Summarize the key content of this image in 1-2 sentences.",
		"Emotion": "Describe the emotions or mood conveyed by this image.",
		"Style": "Describe the artistic or visual style of this image.",
		"Location": "Where might this image be taken? Analyze the setting or location.",
		"Question": "What question could be asked based on this image?",
		"Creative": "Describe this image as if writing the beginning of a short story."
	},
	"gguf_models": {
		"MiniCPM-V-4 (Q4_0)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q4_0.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.08 GB - 4-bit quantization"
		},
		"MiniCPM-V-4 (Q4_1)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q4_1.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.29 GB - 4-bit quantization improved"
		},
		"MiniCPM-V-4 (Q4_K_M)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q4_K_M.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.19 GB - 4-bit K-quants medium"
		},
		"MiniCPM-V-4 (Q4_K_S)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q4_K_S.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.09 GB - 4-bit K-quants small"
		},
		"MiniCPM-V-4 (Q5_0)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q5_0.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.51 GB - 5-bit quantization"
		},
		"MiniCPM-V-4 (Q5_1)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q5_1.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.72 GB - 5-bit quantization improved"
		},
		"MiniCPM-V-4 (Q5_K_M)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q5_K_M.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.56 GB - 5-bit K-quants medium"
		},
		"MiniCPM-V-4 (Q5_K_S)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q5_K_S.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.51 GB - 5-bit K-quants small"
		},
		"MiniCPM-V-4 (Q6_K)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q6_K.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "2.96 GB - 6-bit quantization"
		},
		"MiniCPM-V-4 (Q8_0)": {
			"name": "openbmb/MiniCPM-V-4-gguf/ggml-model-Q8_0.gguf",
			"mmproj": "openbmb/MiniCPM-V-4-gguf/mmproj-model-f16.gguf",
			"description": "3.83 GB - 8-bit quantization, highest quality"
		},
		"MiniCPM-V-2.6 (Q2_K)": {
			"name": "openbmb/MiniCPM-V-2_6-gguf/ggml-model-Q2_K.gguf",
			"mmproj": "openbmb/MiniCPM-V-2_6-gguf/mmproj-model-f16.gguf",
			"description": "3.01 GB - Smallest size, lowest quality"
		},
		"MiniCPM-V-2.6 (Q3_K_S)": {
			"name": "openbmb/MiniCPM-V-2_6-gguf/ggml-model-Q3_K_S.gguf",
			"mmproj": "openbmb/MiniCPM-V-2_6-gguf/mmproj-model-f16.gguf",
			"description": "3.49 GB - 3-bit small, good for low-end hardware"
		},
		"MiniCPM-V-2.6 (Q3_K_M)": {
			"name": "openbmb/MiniCPM-V-2_6-gguf/ggml-model-Q3_K_M.gguf",
			"mmproj": "openbmb/MiniCPM-V-2_6-gguf/mmproj-model-f16.gguf",
			"description": "3.81 GB - 3-bit medium, balanced for low-end hardware"
		},
		"MiniCPM-V-2.6 (Q4_0)": {
			"name": "openbmb/MiniCPM-V-2_6-gguf/ggml-model-Q4_0.gguf",
			"mmproj": "openbmb/MiniCPM-V-2_6-gguf/mmproj-model-f16.gguf",
			"description": "4.43 GB - Classic 4-bit quantization"
		}
	}
}